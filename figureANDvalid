clc; clear ; close all;


%% ====== 模擬設定 ======
n = 500;       % 樣本數
p = 2;         % 預測變量數 (含截距項)
K = 2;         % 組別數量
num_sim = 500; % 模擬次數

% 真實參數值
beta_true  = [1 -1;   % 每行是第k組的beta (第一列是截距)
              1  1];  
alpha_true = [2, 4];  % 形狀參數
pi_true    = [0.5, 0.5]; % 混合比例

% 儲存結果的變數
beta_all  = NaN(num_sim, p, K);
alpha_all = NaN(num_sim, K);
pi_all    = NaN(num_sim, K);
valid_idx = false(num_sim, 1);
loglik_all = NaN(num_sim, 1); % 儲存對數似然值


total_timer = tic;     % 開始總計時器
time_all = NaN(num_sim,1);  % 儲存每次模擬耗時

sim_count = 0; % 計數器

%% ====== 開始模擬 ======
while sim_count < num_sim
    s = sim_count + 1;
    fprintf('模擬進度: %d/%d\n', s, num_sim);
    try
        sim_timer = tic; % 單次模擬計時開始

         % Step 0: 模擬資料
        x_vals = normrnd(0, 1, n, 1);
        X = [ones(n,1), x_vals];
        z = randsample(1:K, n, true, pi_true);
        y = zeros(n,1);
        
        for i=1:n
            k0 = z(i);
            eta = X(i,:) * beta_true(:,k0);
            mu = 1/(1+exp(-eta));
            mu_alpha = mu^(1/alpha_true(k0));
            lambda = mu_alpha/(1-mu_alpha);
            t = gammaincinv(rand(), alpha_true(k0), 'lower');
            y(i) = exp(-t/lambda);
        end
        y = max(y, eps);
        
        % ====== EM Initialization (隨機初始化) ======
        % 隨機初始化tau
        tau = rand(n,K); 
        tau = tau ./ sum(tau,2);
        
        % 初始化參數
        pi_k = mean(tau) + 1e-6; % 避免零概率
        pi_k = pi_k / sum(pi_k);
        
        beta_k = randn(p,K); % 隨機初始化beta
        alpha_k = 1 + 3*rand(1,K); % 隨機初始化alpha在[1,4]範圍內
        
        % EM參數
        reg = 1e-6;
        max_iter = 300;
        tol = 1e-6;
        converged = false;
        prev_loglik = -Inf;
        loglik_trace = zeros(max_iter,1);
        
        % ====== EM算法主循環 ======
        for iter = 1:max_iter
            % --- E-step ---
            dens = zeros(n,K);
            for j = 1:K
                eta = X * beta_k(:,j); %1000*2x2*1=1000*1
                mu = 1./(1+exp(-eta));
                mu_alpha = mu.^(1/alpha_k(j));
                lambda = mu_alpha./(1-mu_alpha);
                
                logpdf = alpha_k(j)*log(lambda) - gammaln(alpha_k(j)) + ...
                         (lambda-1).*log(y) + (alpha_k(j)-1).*log(-log(y));
                dens(:,j) = pi_k(j) * exp(logpdf);
            end
            loglik = sum(log(sum(dens,2)));
            loglik_trace(iter) = loglik;
            tau = dens ./ (sum(dens,2) + eps);
            
            % --- M-step: 更新pi ---
            Nk = sum(tau,1);
            pi_new = Nk / n;
            
            % --- M-step: 更新beta (使用Fisher scoring) ---
            beta_new = beta_k;
            for j = 1:K
                b_curr = beta_k(:,j);
                a_curr = alpha_k(j);
                
                for newton_iter = 1:10 % 內部牛頓迭代
                    eta = X * b_curr;
                    mu = 1./(1+exp(-eta));
                    mu = max(min(mu, 1-eps), eps);
                    
                    mu_alpha = mu.^(1/a_curr);
                    one_mu = max(1 - mu_alpha, eps);
                    lambda = mu_alpha ./ one_mu;
                    lny = log(y + eps);
                    
                    % 計算分數函數
                    term1 = (1-mu)./one_mu;
                    term2 = (mu_alpha.*(1-mu).*lny)./(a_curr*(one_mu).^2);
                    score = sum(tau(:,j).*(term1 + term2).*X, 1)';
                    
                    % 計算Fisher信息矩陣
                    fisher = zeros(p,p);
                    for i=1:n
                        xi = X(i,:)';
                        fisher = fisher + tau(i,j)*((1-mu(i))^2)/(a_curr*(one_mu(i))^2)*(xi*xi'); %矩陣總和
                    end
                    fisher = fisher + reg*eye(p);
                    
                    % 更新beta
                    if rcond(fisher) > eps
                        delta_1 = fisher \ score;%矩陣除法 （反矩陣）
                    else
                        delta_1 = pinv(fisher) * score;%矩陣不可逆時的最佳做法A+
                    end
                    
                    % 限制更新步長
                    step_size = min(1, 1/norm(delta_1)); %兩個取小
                    b_curr = b_curr + step_size * delta_1;
                end
                beta_new(:,j) = b_curr;
            end
            
            % --- M-step: 更新alpha ---
            alpha_new = alpha_k;
            for j = 1:K
                delta = log(alpha_k(j)); % 使用log轉換確保alpha>0
                
                for newton_iter = 1:10
                    alpha = exp(delta);
                    eta = X * beta_new(:,j);
                    mu = 1./(1+exp(-eta));
                    mu_alpha = mu.^(1/alpha);
                    one_mu = 1 - mu_alpha;
                    lny = log(y); 
                    logu = log(mu); 
                    loglogy = log(-log(y));
                    
                    % 計算分數函數
                    d_ll_dalpha = -logu./(alpha^2 .* one_mu);
                    d_lambda = (mu_alpha./one_mu) .* d_ll_dalpha;
                    term1 = log(mu_alpha./one_mu);
                    term2 = d_ll_dalpha .* alpha;
                    term3 = d_lambda .* lny;
                    dlogpdf = term1 + term2 + term3 - psi(alpha) + loglogy;
                    score_a = alpha * sum(tau(:,j) .* dlogpdf);
                    
                    % 計算Fisher信息
                    trig = psi(1,alpha);
                    t1 = -(logu.*(2*alpha - logu - 2*alpha.*mu_alpha)) ./ (alpha .* one_mu.^2);
                    t2 = alpha^2*trig;
                    t3 = alpha*psi(alpha);
                    t4 = -alpha*log(log(1./y));
                    t5 = -alpha*log(mu_alpha./one_mu);
                    fisher_a = sum(tau(:,j).*(t1+t2+t3+t4+t5)) + reg; %標量總和
                    
                    % 更新alpha
                    delta = delta + score_a / fisher_a;
                end
                alpha_new(j) = exp(delta);
            end
            
            % --- 收斂檢查 ---
            % Step 6: Check convergence using separate L2 norms for each parameter group
            change_pi = norm(pi_new - pi_k);           % L2 norm of mixing proportions
            change_beta = norm(beta_new(:) - beta_k(:)); % L2 norm of regression coefficients
            change_alpha = norm(alpha_new - alpha_k);  % L2 norm of alpha parameters

            param_change = change_pi + change_beta + change_alpha;

            if param_change < tol && iter > 10
               converged = true;
               break;
            end

            % 更新參數
            pi_k = pi_new;
            beta_k = beta_new;
            alpha_k = alpha_new;
            prev_loglik = loglik;
        end
        
        % === 解決label switching問題 ===
        % 根據截距項排序 
        [~, sort_idx] = sort(beta_k(1,:));
        pi_k = pi_k(sort_idx);
        beta_k = beta_k(:,sort_idx);
        alpha_k = alpha_k(sort_idx);
        
        % 與真實參數對齊 
        % 計算所有可能的排列組合
        permutations = perms(1:K);
        best_dist = Inf;
        best_perm = 1:K;
        
        for perm_idx = 1:size(permutations,1)
            perm = permutations(perm_idx,:);
            
            % 計算距離度量 (結合beta和alpha的差異)
            dist = norm(beta_k(:,perm) - beta_true, 'fro') + ...
                   norm(alpha_k(perm) - alpha_true);
            
            if dist < best_dist
                best_dist = dist;
                best_perm = perm;
            end
        end
        
        % 重新排列估計參數
        pi_k = pi_k(best_perm);
        beta_k = beta_k(:,best_perm);
        alpha_k = alpha_k(best_perm);

        % === 儲存結果 ===
        if converged && all(isfinite(pi_k)) && all(isfinite(alpha_k)) && all(isfinite(beta_k(:)))
            sim_count = sim_count + 1;
            pi_all(sim_count,:) = pi_k;
            beta_all(sim_count,:,:) = beta_k;
            alpha_all(sim_count,:) = alpha_k;
            loglik_all(sim_count) = loglik;
            valid_idx(sim_count) = true;
            time_all(sim_count) = toc(sim_timer);
        end

    catch ME
        fprintf('模擬 %d 出錯: %s\n', s, ME.message);
        continue;
    end
end


total_time = toc(total_timer);
fprintf('\n模擬總耗時：%.2f 秒\n', total_time);
fprintf('平均每次模擬耗時：%.2f 秒\n', mean(time_all(valid_idx)));
fprintf('有效模擬次數：%d / %d\n', sum(valid_idx), num_sim);
fprintf('模擬 %d 完成，log-likelihood = %.6f\n', s, loglik);

%% ===== 統計結果 =====
valid_runs = sum(valid_idx);
if valid_runs == 0
    error('沒有有效的模擬結果！');
end

% 提取有效結果
pi_valid = pi_all(valid_idx,:);
beta_valid = beta_all(valid_idx,:,:);
alpha_valid = alpha_all(valid_idx,:);

% ===== 計算統計量 =====
n_valid = size(pi_valid, 1);  % 模擬次數

% 平均值
pi_mean = mean(pi_valid, 1);
beta_mean = squeeze(mean(beta_valid, 1));
alpha_mean = mean(alpha_valid, 1);

% 標準差
pi_std = std(pi_valid, [], 1);
beta_std = squeeze(std(beta_valid, [], 1));
alpha_std = std(alpha_valid, [], 1);

% 標準誤（Standard Error）＝ 標準差 / sqrt(n)
pi_se = pi_std / sqrt(n_valid);
beta_se = beta_std / sqrt(n_valid);
alpha_se = alpha_std / sqrt(n_valid);

% 偏差
pi_bias = pi_mean - pi_true;
beta_bias = beta_mean - beta_true;
alpha_bias = alpha_mean - alpha_true;

% RMSE
pi_rmse = sqrt(mean((pi_valid - pi_true).^2, 1));
beta_rmse = squeeze(sqrt(mean((beta_valid - reshape(beta_true,1,p,K)).^2, 1)));
alpha_rmse = sqrt(mean((alpha_valid - alpha_true).^2, 1));


%% ===== 顯示結果 =====
fprintf('\n======== 模擬結果 ========\n');

fprintf('\n== 真實參數 ==\n');
fprintf('混合比例 pi:    [%.2f, %.2f]\n', pi_true(1), pi_true(2));
fprintf('回歸係數 beta:\n');
disp(beta_true);
fprintf('形狀參數 alpha: [%.2f, %.2f]\n', alpha_true(1), alpha_true(2));

fprintf('\n== 估計結果 (平均值 ± 標準誤) ==\n');
fprintf('混合比例 pi:    [%.4f ± %.4f, %.4f ± %.4f]\n', ...
        pi_mean(1), pi_se(1), pi_mean(2), pi_se(2));
    
fprintf('\n回歸係數 beta:\n');
for k = 1:K
    fprintf('組別 %d:\n', k);
    for p_idx = 1:p
        fprintf('  beta%d: %.4f ± %.4f\n', p_idx-1, ...
                beta_mean(p_idx,k), beta_se(p_idx,k));
    end
end

fprintf('\n形狀參數 alpha: [%.4f ± %.4f, %.4f ± %.4f]\n', ...
        alpha_mean(1), alpha_se(1), alpha_mean(2), alpha_se(2));

fprintf('\n== 偏差與RMSE ==\n');
fprintf('混合比例 pi:\n');
fprintf('  偏差: [%.4f, %.4f]\n', pi_bias(1), pi_bias(2));
fprintf('  RMSE: [%.4f, %.4f]\n', pi_rmse(1), pi_rmse(2));

fprintf('\n回歸係數 beta:\n');
for k = 1:K
    fprintf('組別 %d:\n', k);
    for p_idx = 1:p
        fprintf('  beta%d: 偏差=%.4f, RMSE=%.4f\n', p_idx-1, ...
                beta_bias(p_idx,k), beta_rmse(p_idx,k));
    end
end

fprintf('\n形狀參數 alpha:\n');
fprintf('  偏差: [%.4f, %.4f]\n', alpha_bias(1), alpha_bias(2));
fprintf('  RMSE: [%.4f, %.4f]\n', alpha_rmse(1), alpha_rmse(2));

%% ====== Visualization: Combined True Groups + Estimated Regression Lines ======
figure('Position', [100, 100, 900, 500]); % 畫面寬一點

hold on;

% 定義組別顏色（Group 1: 紅色, Group 2: 藍色）
group_colors = {'r', 'b'};

% 圖示設定
markersize = 20; 
estimated_linewidth = 3;
true_linewidth = 1.5;

% --- 畫出真實資料點 ---
for j = 1:K
    idx = (z == j);
    scatter(X(idx,2), y(idx), markersize, ...
            'MarkerFaceColor', group_colors{j}, ...
            'MarkerEdgeColor', 'k', ...
            'MarkerFaceAlpha', 0.7, ...
            'DisplayName', sprintf('Group %d', j));
end

% 建立 x 網格點
x_grid = linspace(min(X(:,2)) - 0.5, max(X(:,2)) + 0.5, 300)';
X_grid = [ones(size(x_grid)), x_grid];

% --- 畫估計的回歸線（紅線/藍線） ---
for j = 1:K
    mu_est = 1 ./ (1 + exp(-X_grid * beta_k(:,j)));
    plot(x_grid, mu_est, '-', 'LineWidth', estimated_linewidth, ...
         'Color', group_colors{j}, ...
         'DisplayName', sprintf('est: Group %d', j));
end

% --- 畫真實模型的回歸線（黑虛線，僅標示一次）---
for j = 1:K
    mu_true = 1 ./ (1 + exp(-X_grid * beta_true(:,j)));
    if j == 1
        plot(x_grid, mu_true, '--k', 'LineWidth', true_linewidth, ...
             'DisplayName', 'True Model Lines');
    else
        plot(x_grid, mu_true, '--k', 'LineWidth', true_linewidth, ...
             'HandleVisibility','off');
    end
end

% --- 圖示設定 ---
xlabel('x', 'FontSize', 14);
ylabel('u', 'FontSize', 14);
legend('Location','bestoutside', 'FontSize', 10);
grid on; box on; hold off;


